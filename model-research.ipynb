{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1c09a-902a-49d7-b5ae-837afa001180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514ac7d6-84f1-4751-8cbd-63cd5c69860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 16:55:37.414689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-27 16:55:37.457450: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-27 16:55:37.469531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e98f91-4002-4421-9426-fbaf19d6e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = './data/train'\n",
    "train_masks_path = './data/train-masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f488d4-3931-4efa-b406-ecd61ef2d1d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train/2369_jpg.rf.8b8afa9d79c61fa42ca128c940b9cbc0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# there is no annotations for this file in .json\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO: make check on this file if exists\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/train/2369_jpg.rf.8b8afa9d79c61fa42ca128c940b9cbc0.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train/2369_jpg.rf.8b8afa9d79c61fa42ca128c940b9cbc0.jpg'"
     ]
    }
   ],
   "source": [
    "# there is no annotations for this file in .json\n",
    "# TODO: make check on this file if exists\n",
    "if not os.remove('./data/train/2369_jpg.rf.8b8afa9d79c61fa42ca128c940b9cbc0.jpg'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742d9bb9-69bd-4fc8-aaa4-9eedefc74940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating masks...\n",
      "Generated 1502 masks\n",
      "Resized directory with name `./data/train` to 128x128 images\n",
      "Resized directory with name `./data/train-masks` to 128x128 images\n"
     ]
    }
   ],
   "source": [
    "from data_clean import DataClean\n",
    "\n",
    "dc = DataClean()\n",
    "dc.resize_img_dir_128(train_images_path)\n",
    "dc.resize_img_dir_128(train_masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7c845-54b6-4ea1-8571-921da7867b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_images_from_folder(folder, target_size=(128, 128), grayscale=False):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.coco.json'):\n",
    "            continue\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = load_img(img_path, target_size=target_size, color_mode='grayscale' if grayscale else 'rgb')\n",
    "            img = img_to_array(img)\n",
    "            images.append(img)\n",
    "        except:\n",
    "            print(f\"Cannot identify image file {img_path}. Skipping.\")\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961c47d-d102-4eb2-add7-bcb19968bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_images_from_folder(train_images_path)\n",
    "y_train = load_images_from_folder(train_masks_path, target_size=(128, 128), grayscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cb8b9-5e62-4914-854a-24536316cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e84eee-b1c5-4900-937a-564a2d85db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_train) != len(y_train):\n",
    "    raise ValueError(f\"Number of training images ({len(X_train)}) and masks ({len(y_train)}) do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f111aee-7982-4bc4-afd3-4ee5504457c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "y_train = y_train / 255.0\n",
    "y_train = np.round(y_train) # Перетворення масок у бінарний формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556add2-a256-41e3-86f2-5a55f1949e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414cdbff-edba-4ead-9522-caf90e663890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_net_model(input_size=(128, 128, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    p5 = layers.MaxPooling2D((2, 2))(c5)\n",
    "\n",
    "    u6 = layers.Conv2DTranspose(256, (2,2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2,2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2,2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2,2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    res = layers.Conv2D(1, (1, 1), activation='sigmoid')(c1)\n",
    "    return models.Model(inputs=[inputs], outputs=[res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3dc5b8-9c3b-4abe-865f-9d1e0bbdd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = u_net_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715d039-ec7d-4a6b-b952-187a01876c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6024d-1fb5-4e67-99b8-7c7db5b1545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
